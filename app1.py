# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Paw2ClSI4assylE7J7pEIdJJE7R4yVEf
"""

import os
import streamlit as st
import noisereduce as nr
import librosa
import soundfile as sf
import numpy as np
import whisper
import whisperx
from whisperx.diarize import DiarizationPipeline
from fpdf import FPDF
from datetime import datetime
from openai import OpenAI
from deep_translator import GoogleTranslator
import base64
import io

st.set_page_config(page_title="Meeting Notes Generator", layout="centered")

# Full CSS Styling
st.markdown(
    """
    <style>
    .stApp {
        background-color: #151515 !important;
        min-height: 100vh;
    }
    .main > div {
        background: rgba(30, 30, 30, 0.96);
        border-radius: 16px;
        box-shadow: 0 6px 24px 0 rgba(125, 111, 152, 0.11);
        margin: 2rem auto;
        padding: 2.2rem 2rem 1.5rem 2rem;
        max-width: 650px;
    }
    h1, .stMarkdown h1 {
        font-family: 'Playfair Display', serif;
        background: linear-gradient(90deg, #d3cbb8 0%, #7952b3 94%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        font-size: 2.6rem;
        font-weight: 700;
        margin-top: 1.2em;
        margin-bottom: 1.3em;
        letter-spacing: 1px;
    }
    .stButton button {
        color: #fff;
        background: linear-gradient(90deg, #a770ef 0%, #f6d365 100%);
        border: none;
        border-radius: 8px;
        padding: 0.5em 1.7em;
        font-size: 1.1rem;
        font-family: 'Segoe UI', Arial, sans-serif;
        box-shadow: 0 2px 10px rgba(159,123,240,0.14);
        transition: 0.3s all;
    }
    .stButton button:hover {
        background: linear-gradient(90deg, #f6d365 0%, #a770ef 100%);
        color: #2f2f2f;
        box-shadow: 0 6px 16px rgba(159,123,240,0.20);
        transform: translateY(-2px) scale(1.02);
    }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True
)

st.image(
    "https://images.pexels.com/photos/3183183/pexels-photo-3183183.jpeg",
    use_container_width=True,
    width=330,
    caption="Your classic workspace"
)

st.title("Automatic Meeting Notes Generator")

hug_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")
together_token = os.getenv("TOGETHER_API_KEY")

for key in ["step", "transcript", "result", "diarization_text", "human_summary", "translated_summary"]:
    if key not in st.session_state:
        st.session_state[key] = None

if st.session_state.step is None:
    st.session_state.step = 1

audio = st.file_uploader("Upload a meeting audio file", type=["wav", "mp3"])

if st.session_state.step == 1:
    if audio is not None:
        with open("input.wav", "wb") as f:
            f.write(audio.read())
        st.success("Audio uploaded successfully!")

        if st.button("Start Processing"):
            with st.spinner("Reducing noise and transcribing..."):
                try:
                    audio_data, sample_rate = librosa.load("input.wav", sr=None)
                    chunk_samples = int(60 * sample_rate)
                    noise = audio_data[:sample_rate]
                    denoised_audio = []

                    for start in range(0, len(audio_data), chunk_samples):
                        end = min(start + chunk_samples, len(audio_data))
                        curr_chunk = audio_data[start:end]
                        reduced_chunk = nr.reduce_noise(y=curr_chunk, sr=sample_rate, y_noise=noise)
                        denoised_audio.append(reduced_chunk)

                    denoised_audio = np.concatenate(denoised_audio)
                    sf.write("denoised.wav", denoised_audio, sample_rate)
                except Exception as e:
                    st.error(f"Noise reduction failed: {e}")
                    st.stop()

            try:
                model = whisper.load_model("tiny")
                transcription_result = model.transcribe("denoised.wav", task="translate")
                st.session_state.result = transcription_result
                st.session_state.transcript = transcription_result["text"]
                st.session_state.step = 2
                st.rerun()
            except Exception as e:
                st.error(f"Transcription failed: {e}")

elif st.session_state.step == 2:
    if st.session_state.result is not None:
        st.text_area("Detected language:", st.session_state.result.get("language", "Unknown"))
        st.text_area("Transcript", st.session_state.transcript, height=200)

        st.subheader("Generate meeting summary")
        prompt1 = f"""
You are a professional meeting summarizer and executive assistant.

Given the following transcript, generate a **high-quality, structured meeting summary** in natural, flowing paragraphs that reads as if written by a human assistant. Your summary should cover the following sections clearly and cohesively:

1. **Title** – A concise, descriptive title for the meeting (can include topic or theme).
2. **Participants** – List the main attendees and their roles (if known).
3. **Introduction** – State the purpose, setting, and timing of the meeting.
4. **Main Discussion** – Summarise the key points discussed, grouped logically by topics. Include any notable quotes or references to who said what, if available.
5. **Decisions Made** – Clearly explain outcomes or agreements reached. Embed them naturally within the discussion or call them out separately.
6. **Action Items & Assignments** – Describe tasks, responsibilities, and (if present) deadlines. Try to include the responsible person's name or role.
7. **Unresolved Questions or Follow-Ups** – Mention any issues that require further investigation or discussion.
8. **Conclusion** – Wrap up with the general outcome or next direction, highlighting achievements or challenges.

**Guidelines:**
- Write in professional, British English.
- Use well-organised paragraphs, not bullet points unless necessary for clarity (like in Action Items).
- Avoid repeating filler words or exact transcript text.
- Do not make up facts not present in the transcript.
- If the transcript includes timestamps or speaker names, use them selectively for clarity and attribution.
- If relevant, estimate approximate timestamps for key decisions or moments using context.

Transcript:
{st.session_state.transcript}
"""

        if st.button("Generate Summary"):
            with st.spinner("Generating summary with LLaMA-3..."):
                try:
                    client = OpenAI(
                        base_url="https://api.together.xyz/v1",
                        api_key=together_token
                    )
                    response = client.chat.completions.create(
                        model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
                        messages=[{"role": "user", "content": prompt1}],
                        max_tokens=1100,
                        temperature=0.3,
                    )
                    first_summary = response.choices[0].message.content

                    second_prompt = f"""
You are a skilled executive assistant refining the output of an AI-generated meeting summary.

Your task is to improve tone, flow, and clarity without losing structure or information. You should polish the writing to make it sound more natural, more human, and professional – as if it’s being prepared for a senior manager or team leader.

**Your Goals:**
- Improve sentence structure and word flow.
- Convert robotic or abrupt lines into fluent, well-written English.
- Maintain the section headers (e.g., Introduction, Main Discussion, etc.).
- Use paragraph form mostly, but retain bullet points where they add clarity (e.g., in Action Items or Unresolved Questions).
- Preserve accuracy of content — don’t invent anything.
- Keep a professional, business-like tone (British English), but avoid sounding stiff or too generic.
- Length should be proportionate to a 30-minute meeting.

Here is the AI-generated summary to refine:
{first_summary}
"""
                    human_response = client.chat.completions.create(
                        model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
                        messages=[{"role": "user", "content": second_prompt}],
                        max_tokens=4096,
                        temperature=0.3,
                    )
                    st.session_state.human_summary = human_response.choices[0].message.content
                    st.session_state.step = 3
                    st.rerun()
                except Exception as e:
                    st.error(f"Summarisation failed: {str(e)}")

        if st.button("Run Speaker Diarization"):
            with st.spinner("Identifying speakers..."):
                try:
                    model = whisperx.load_model("large-v2", device="cpu", compute_type="int8")
                    device = "cpu"
                    diarization_model = DiarizationPipeline(use_auth_token=hug_token, device=device)
                    diarization_segments = diarization_model("denoised.wav")
                    assign_speakers = whisperx.assign_word_speakers(diarization_segments, st.session_state.result)

                    diarization_text = ""
                    for seg in assign_speakers["segments"]:
                        speaker_label = seg.get('speaker', 'Unknown')
                        diarization_text += f"[{seg['start']:.2f} ~ {seg['end']:.2f}] Speaker {speaker_label}: {seg['text']}\n"

                    st.session_state.diarization_text = diarization_text
                    st.success("Speaker diarization complete!")
                    st.text_area("Speaker Diarized Transcript", diarization_text, height=250)
                except Exception as e:
                    st.error(f"Speaker diarization failed: {e}")

elif st.session_state.step == 3:
    if st.session_state.human_summary:
        st.success("Summarisation complete!")
        st.subheader("Humanised Summary")
        st.text_area("Human-style Summary", st.session_state.human_summary, height=250)

        choose_lang = st.selectbox("Choose a language", ["None", "hi", "te", "ta", "kn", "mr", "bn"])

        if choose_lang != "None":
            if st.button("Translate Summary"):
                try:
                    translator = GoogleTranslator()
                    translated = translator.translate(st.session_state.human_summary, src='en', target=choose_lang)
                    st.session_state.translated_summary = translated
                    st.rerun()
                except Exception as e:
                    st.error(f"Translation failed: {str(e)}")

        if st.session_state.translated_summary:
            st.text_area("Translated Summary", st.session_state.translated_summary, height=200)

        class PDF(FPDF):
            def header(self):
                self.set_font("Helvetica", "B", 16)
                self.set_text_color(40, 40, 100)
                self.cell(0, 10, "Automated Meeting Summary", ln=True, align="C")
                self.set_font("Helvetica", "", 12)
                self.set_text_color(100, 100, 100)
                self.cell(0, 10, f"Generated on {datetime.now().strftime('%d %b %Y, %I:%M %p')}", ln=True, align="C")
                self.ln(5)

            def section_title(self, title):
                self.ln(10)
                self.set_font("Helvetica", "B", 14)
                self.set_text_color(30, 30, 30)
                self.cell(0, 10, title, ln=True)
                self.set_draw_color(180, 180, 180)
                self.line(10, self.get_y(), 200, self.get_y())
                self.ln(4)

            def section_body(self, text):
                self.set_font("Helvetica", "", 12)
                self.set_text_color(50, 50, 50)
                self.multi_cell(0, 8, text)
                self.ln(2)

        if st.button("Download PDF"):
            pdf = PDF()
            pdf.add_page()
            pdf.section_title("AUTOMATED MEETING SUMMARY")
            summary_text = st.session_state.translated_summary or st.session_state.human_summary
            pdf.section_body(summary_text)

            pdf_buffer = io.BytesIO()
            pdf.output(pdf_buffer, 'F')
            pdf_buffer.seek(0)

            st.download_button("Download Summary PDF", data=pdf_buffer, file_name="meeting_summary.pdf", mime='application/pdf')
           
          # if st.session_state.diarization_text:
      #  st.subheader("Speaker Diarization Result")
       # st.text_area("", st.session_state.diarization_text, height=300)
